{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 SageMaker Pipelines 创建自动模型Fine-Tuning工作流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1'></a>\n",
    "## Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, check that the correct kernel is chosen.\n",
    "\n",
    "<img src=\"img/kernel_set_up.png\" width=\"300\"/>\n",
    "\n",
    "You can click on that to see and check the details of the image, kernel, and instance type.\n",
    "\n",
    "<img src=\"img/w3_kernel_and_instance_type.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:  THIS NOTEBOOK WILL TAKE ABOUT 30 MINUTES TO COMPLETE.\n",
    "\n",
    "# PLEASE BE PATIENT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Pipelines\n",
    "\n",
    "亚马逊 SageMaker Pipelines 支持以下内容：\n",
    "\n",
    "* **Pipelines** - 编排 SageMaker 作业和资源创建的步骤和条件的定向无环图。\n",
    "* **处理作业步骤** - 在 SageMaker 上运行数据处理工作负载（例如特征工程、数据验证、模型评估和模型解释）的简化托管体验。\n",
    "* **Training Job Steps** - 一个迭代过程，通过展示训练数据集中的示例，教导模型做出预测。\n",
    "* **条件步骤** - 提供管道中分支的条件执行。\n",
    "* **注册模型** - 在模型注册表中创建模型包资源，该资源可用于在 Amazon SageMaker 中创建可部署的模型。\n",
    "* **参数化执行** - 允许管道执行因提供的参数而异。\n",
    "* **Transform Job Steps** - 一种批量变换，用于预处理数据集，以消除干扰数据集训练或推理的噪音或偏见，从大型数据集中获取推断，并在不需要永久端点时运行推理。\n",
    "\n",
    "# 设计Pipeline\n",
    "\n",
    "在处理步骤中，我们使用 HuggingFace/ 中的 “transformer” 库执行特征工程来标记我们的对话输入\n",
    "\n",
    "在训练步骤中，我们对模型进行了微调，以便在 “diagsum” 数据集中有效地总结对话。\n",
    "\n",
    "在评估步骤中，我们将经过微调的模型和测试数据集作为输入，并生成一个包含基于 ROUGE 指标的评估指标的 JSON 文件进行汇总。\n",
    "\n",
    "在条件步骤中，如果模型的指标（由我们的评估步骤确定）超过某个值，我们将决定是否注册此模型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmem(total=33229983744, available=16399966208, percent=50.6, used=16420958208, free=3103346688, active=17451048960, inactive=11602255872, buffers=1634304, cached=13704044544, shared=1429504, slab=844406784)\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "print(notebook_memory)\n",
    "\n",
    "if notebook_memory.total < 32 * 1000 * 1000 * 1000:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError\n",
    "\n",
    "import os\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "import botocore.config\n",
    "\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra='dsoaws/2.0'\n",
    ")\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", \n",
    "                            region_name=region,\n",
    "                            config=config)\n",
    "s3 = boto3.Session().client(service_name=\"s3\", \n",
    "                            region_name=region,\n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置 S3 源位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    raw_input_data_s3_uri\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE PREVIOUS NOTEBOOK \")\n",
    "    print(\"You did not have the required datasets.       \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-941797585610/data-summarization/\n"
     ]
    }
   ],
   "source": [
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "if not raw_input_data_s3_uri:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN THE PREVIOUS NOTEBOOK \")\n",
    "    print(\"You did not have the required datasets.       \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "else:\n",
    "    print(\"[OK]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将管道作为 “实验” 进行跟踪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception\n",
      "Created Pipeline Name: dialogue-summary-pipeline-1694260461\n"
     ]
    }
   ],
   "source": [
    "# 初始设置正在运行的管道执行和已完成的管道执行的数量为0\n",
    "running_executions = 0\n",
    "completed_executions = 0\n",
    "\n",
    "try:\n",
    "    # 使用 'list_pipeline_executions' 方法获取指定管道的所有执行信息\n",
    "    # 'PipelineName' 参数指定了管道的名称\n",
    "    # 'SortOrder' 参数指定了排序顺序，这里设为 \"Descending\"，即按降序排序\n",
    "    existing_pipeline_executions_response = sm.list_pipeline_executions(\n",
    "        PipelineName=pipeline_name,\n",
    "        SortOrder=\"Descending\",\n",
    "    )\n",
    "\n",
    "    # 检查响应中是否包含 'PipelineExecutionSummaries' 键\n",
    "    # 如果包含，说明获取到了管道执行信息\n",
    "    if \"PipelineExecutionSummaries\" in existing_pipeline_executions_response.keys():\n",
    "        # 如果管道执行信息的数量大于0，进一步处理第一个执行信息\n",
    "        if len(existing_pipeline_executions_response[\"PipelineExecutionSummaries\"]) > 0:\n",
    "            execution = existing_pipeline_executions_response[\"PipelineExecutionSummaries\"][0]\n",
    "            # 检查执行信息中是否包含 'PipelineExecutionStatus' 键\n",
    "            # 如果包含，根据状态更新正在运行和已完成的执行数量\n",
    "            if \"PipelineExecutionStatus\" in execution:\n",
    "                if execution[\"PipelineExecutionStatus\"] == \"Executing\":\n",
    "                    running_executions = running_executions + 1\n",
    "                else:\n",
    "                    completed_executions = completed_executions + 1\n",
    "\n",
    "            # 打印出正在运行和已完成的执行数量\n",
    "            print(\n",
    "                \"[INFO] You have {} Pipeline execution(s) currently running and {} execution(s) completed.\".format(\n",
    "                    running_executions, completed_executions\n",
    "                )\n",
    "            )\n",
    "    # 如果响应中不包含 'PipelineExecutionSummaries' 键，打印出提示信息\n",
    "    else:\n",
    "        print(\"[OK] Please continue.\")\n",
    "# 如果尝试获取执行信息时发生异常，忽略异常\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# 如果没有正在运行的执行，创建一个新的管道名称，然后打印出这个名称\n",
    "if running_executions == 0:\n",
    "    timestamp = int(time.time())\n",
    "    pipeline_name = \"dialogue-summary-pipeline-{}\".format(timestamp)\n",
    "    print(\"Created Pipeline Name: \" + pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue-summary-pipeline-1694260461\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pipeline_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store pipeline_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker Experiments 是 Amazon SageMaker 的一个功能，它允许你组织、跟踪和比较你的机器学习 (ML) 训练实验。\n",
    "\n",
    "每个 SageMaker Experiment 是一系列的训练作业，这些作业可能有共享的目标（例如，优化相同的模型架构），但有不同的超参数或输入数据。你可以创建一个新的 Experiment，添加训练作业（被称为 \"trial\"）到这个 Experiment，然后比较这些 trial 的结果来找出最佳的模型配置。\n",
    "\n",
    "每个 trial 都包含一个或多个 trial components，这些组件可以代表数据预处理步骤、训练步骤或模型评估步骤。你可以在 trial 之间共享 trial components，这样就可以跟踪和比较不同步骤的效果。\n",
    "\n",
    "SageMaker Experiments 还提供了一个 SDK，你可以用这个 SDK 在 Python 脚本中创建和管理 Experiments 和 trials。你也可以使用 SageMaker Studio，这是一个基于 Web 的 IDE，它提供了一个可视化界面来查看和比较 Experiments 和 trials 的结果。\n",
    "\n",
    "总的来说，SageMaker Experiments 是一个强大的工具，它可以帮助你更有效地进行机器学习模型的迭代和优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias pipeline_experiment_name\n",
      "Created Pipeline Experiment Name: dialogue-summary-pipeline-1694260461\n"
     ]
    }
   ],
   "source": [
    "# 使用 IPython 的 %store 命令从 notebook 的全局环境中恢复 'pipeline_experiment_name' 变量\n",
    "%store -r pipeline_experiment_name\n",
    "\n",
    "# 从 'smexperiments.experiment' 包中导入 'Experiment' 类\n",
    "# 'Experiment' 类是用于在 SageMaker Experiments 中创建和管理实验的类\n",
    "from smexperiments.experiment import Experiment\n",
    "\n",
    "# 使用 'Experiment.create' 方法创建一个新的实验\n",
    "# 'experiment_name' 参数指定了实验的名称，这里使用之前定义的 'pipeline_name' 变量\n",
    "# 'description' 参数指定了实验的描述\n",
    "# 'sagemaker_boto_client' 参数指定了用于与 AWS 服务通信的 Boto3 客户端\n",
    "pipeline_experiment = Experiment.create(\n",
    "    experiment_name=pipeline_name,\n",
    "    description=\"Dialogue Summarization Pipeline Experiment\",\n",
    "    sagemaker_boto_client=sm,\n",
    ")\n",
    "\n",
    "# 获取创建的实验的名称，并保存到 'pipeline_experiment_name' 变量中\n",
    "pipeline_experiment_name = pipeline_experiment.experiment_name\n",
    "\n",
    "# 打印出创建的实验的名称\n",
    "print(\"Created Pipeline Experiment Name: {}\".format(pipeline_experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogue-summary-pipeline-1694260461\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pipeline_experiment_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store pipeline_experiment_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建 `Trial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 smexperiments.trial 包中导入 Trial 类\n",
    "# Trial 类用于在 Amazon SageMaker Experiments 中创建和管理试验\n",
    "# 试验是一种实验的组成部分，通常用于跟踪不同的模型训练作业或模型版本\n",
    "from smexperiments.trial import Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no stored variable or alias pipeline_trial_name\n",
      "Created Trial Name: trial-1694260842\n"
     ]
    }
   ],
   "source": [
    "# 使用 IPython 的 %store 命令从 notebook 的全局环境中恢复 'pipeline_trial_name' 变量\n",
    "%store -r pipeline_trial_name\n",
    "\n",
    "# 获取当前的 Unix 时间戳\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# 使用 'Trial.create' 方法创建一个新的试验\n",
    "# 'trial_name' 参数指定了试验的名称，这里使用 Unix 时间戳创建一个唯一的名称\n",
    "# 'experiment_name' 参数指定了试验所属的实验的名称，这里使用之前创建的实验的名称\n",
    "# 'sagemaker_boto_client' 参数指定了用于与 AWS 服务通信的 Boto3 客户端\n",
    "pipeline_trial = Trial.create(\n",
    "    trial_name=\"trial-{}\".format(timestamp), \n",
    "    experiment_name=pipeline_experiment_name, \n",
    "    sagemaker_boto_client=sm\n",
    ")\n",
    "\n",
    "# 获取创建的试验的名称，并保存到 'pipeline_trial_name' 变量中\n",
    "pipeline_trial_name = pipeline_trial.trial_name\n",
    "\n",
    "# 打印出创建的试验的名称\n",
    "print(\"Created Trial Name: {}\".format(pipeline_trial_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial-1694260842\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'pipeline_trial_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store pipeline_trial_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义参数以参数化管道执行\n",
    "\n",
    "我们定义工作流程参数，通过这些参数可以对管道进行参数化，并更改在流水线执行和计划中注入和使用的值，而无需修改流水线定义。\n",
    "\n",
    "支持的参数类型包括：\n",
    "\n",
    "* `parameterString`-代表一个 `str` Python 类型\n",
    "* `parameterInteger`-表示 “int” Python 类型\n",
    "* `parameterFloat`-表示 “float” Python 类型\n",
    "\n",
    "这些参数支持提供默认值，该值可以在管道执行时被覆盖。指定的默认值应为该参数类型的实例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从 sagemaker.workflow.parameters 模块导入以下类\n",
    "\n",
    "# ParameterString: 用于定义一个字符串参数\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "\n",
    "# ParameterInteger: 用于定义一个整数参数\n",
    "from sagemaker.workflow.parameters import ParameterInteger\n",
    "\n",
    "# ParameterFloat: 用于定义一个浮点数参数\n",
    "from sagemaker.workflow.parameters import ParameterFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-941797585610/data-summarization/\n"
     ]
    }
   ],
   "source": [
    "print(raw_input_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-05 03:06:01    6544107 dialogsum-1.csv\n",
      "2023-09-05 03:06:01    6572423 dialogsum-2.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置 Pipeline 参数\n",
    "这些参数由整个pipeline使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_checkpoint\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the PREPARE section before you continue.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/flan-t5-base\n"
     ]
    }
   ],
   "source": [
    "print(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The default value specified does not match the Parameter Python type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9893d044b054>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m model_checkpoint = ParameterString(\n\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ModelCheckpoint\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/parameters.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, default_value, enum_values)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[1;32m    142\u001b[0m         super(ParameterString, self).__init__(\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mParameterTypeEnum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTRING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menum_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menum_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/parameters.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, parameter_type, default_value)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_validators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0m__attr_validator_default_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__attr_default_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/parameters.py\u001b[0m in \u001b[0;36m_check_default_value\u001b[0;34m(self, _, value)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompatible\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mPython\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \"\"\"\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_default_value_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mRequestType\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/parameters.py\u001b[0m in \u001b[0;36m_check_default_value_type\u001b[0;34m(cls, value, python_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpython_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The default value specified does not match the Parameter Python type.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The default value specified does not match the Parameter Python type."
     ]
    }
   ],
   "source": [
    "# 定义了一个 ParameterString 类型的参数，名为 ModelCheckpoint，并且默认值为 model_checkpoint\n",
    "# 这一参数可以在 SageMaker 工作流中被使用，以便在运行工作流时进行动态配置\n",
    "model_checkpoint = ParameterString(\n",
    "    name=\"ModelCheckpoint\",\n",
    "    default_value=model_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置 Processing 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个名为 \"InputData\" 的字符串参数，它的默认值是 raw_input_data_s3_uri\n",
    "# 这个参数可能被用来指定输入数据的 S3 URI\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=raw_input_data_s3_uri,\n",
    ")\n",
    "\n",
    "# 定义一个名为 \"ProcessingInstanceCount\" 的整数参数，它的默认值是 1\n",
    "# 这个参数可能被用来指定处理步骤的实例数量\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1,\n",
    ")\n",
    "\n",
    "# 定义一个名为 \"ProcessingInstanceType\" 的字符串参数，它的默认值是 \"ml.c5.2xlarge\"\n",
    "# 这个参数可能被用来指定处理步骤的实例类型\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.c5.2xlarge\",\n",
    ")\n",
    "\n",
    "# 定义一个名为 \"TrainSplitPercentage\" 的浮点数参数，它的默认值是 0.90\n",
    "# 这个参数可能被用来指定训练数据集的划分比例\n",
    "train_split_percentage = ParameterFloat(\n",
    "    name=\"TrainSplitPercentage\",\n",
    "    default_value=0.90,\n",
    ")\n",
    "\n",
    "# 定义一个名为 \"ValidationSplitPercentage\" 的浮点数参数，它的默认值是 0.05\n",
    "# 这个参数可能被用来指定验证数据集的划分比例\n",
    "validation_split_percentage = ParameterFloat(\n",
    "    name=\"ValidationSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")\n",
    "\n",
    "# 定义一个名为 \"TestSplitPercentage\" 的浮点数参数，它的默认值是 0.05\n",
    "# 这个参数可能被用来指定测试数据集的划分比例\n",
    "test_split_percentage = ParameterFloat(\n",
    "    name=\"TestSplitPercentage\",\n",
    "    default_value=0.05,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们创建了一个 `sklearnProcessor` 处理器的实例，然后在 `ProcessingStep` 中使用它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "# 从 sagemaker.sklearn.processing 模块导入 SKLearnProcessor 类 \n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# 创建一个 SKLearnProcessor 对象\n",
    "processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",  # 使用的 Scikit-learn 版本\n",
    "    role=role,  # AWS IAM 角色，用于授权 Amazon SageMaker 访问 AWS 资源\n",
    "    instance_type=processing_instance_type,  # 处理任务的实例类型\n",
    "    instance_count=processing_instance_count,  # 处理任务的实例数量\n",
    "    env={\"AWS_DEFAULT_REGION\": region},  # 环境变量，设定 AWS 默认区域\n",
    "    max_runtime_in_seconds=432000,  # 处理任务的最大运行时间（秒）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` ^^ above ^^._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置 Pipeline 步骤缓存\n",
    "使用 [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) 格式将管道步骤缓存一段时间。  \n",
    "\n",
    "有关 SageMaker Pipeline 步骤缓存的更多详细信息在这里：https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines-caching.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在这段代码中，CacheConfig 配置了 SageMaker 工作流步骤的缓存设置\n",
    "# 如果启用缓存 (enable_caching=True)，那么工作流步骤的输出会被缓存起来\n",
    "# 如果后续的工作流运行与之前的运行在输入和参数上完全相同，那么可以直接使用缓存的输出结果，而不用再次运行该步骤\n",
    "\n",
    "# 从 sagemaker.workflow.steps 模块导入 CacheConfig 类\n",
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "# 创建一个 CacheConfig 对象\n",
    "cache_config = CacheConfig(\n",
    "    enable_caching=True,  # 启用缓存\n",
    "    # 缓存的过期时间是用 ISO 8601 格式的时间间隔字符串表示的，这里的 \"PT1H\" 表示缓存的过期时间是1小时。\n",
    "    expire_after=\"PT1H\"  # 缓存的过期时间，这里是1小时后\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，我们使用处理器实例构造一个 `ProcessingStep`，以及输入和输出通道以及将在管道调用管道执行时执行的代码。对于那些熟悉现有 Python SDK 的人来说，这与处理器实例的 `运行` 方法非常相似。\n",
    "\n",
    "请注意作为步骤本身的输入数据传递给 `ProcessingStep` 的 `input_data` 参数。处理器实例在运行时将使用这些输入数据。\n",
    "\n",
    "另外，请注意处理作业的输出配置中指定的 `\"train\"`、`\"validation\"` 和 `\"test\"` 命名通道。这样的步骤 `Properties`可以在后续步骤中使用，并在执行时解析为其运行时值。特别是，我们将在定义训练步骤时提及这种用法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProcessingStep(name='Processing', display_name=None, description=None, step_type=<StepTypeEnum.PROCESSING: 'Processing'>, depends_on=None)\n"
     ]
    }
   ],
   "source": [
    "# 在这段代码中，ProcessingStep 配置了一个数据预处理步骤的执行环境，包括输入、输出、执行的脚本、处理器、参数和缓存配置等\n",
    "# 最后，这段代码打印了处理步骤的信息，以供查看和确认\n",
    "\n",
    "# 从 sagemaker.processing 模块导入 ProcessingInput 和 ProcessingOutput 类\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# 从 sagemaker.workflow.steps 模块导入 ProcessingStep 类\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "# 定义处理步骤的输入\n",
    "processing_inputs = [\n",
    "    ProcessingInput(\n",
    "        input_name=\"raw-input-data\",  # 输入的名称\n",
    "        source=input_data,  # 输入的 S3 URI\n",
    "        destination=\"/opt/ml/processing/input/data/\",  # 在处理容器内的目标目录\n",
    "        s3_data_distribution_type=\"ShardedByS3Key\",  # 数据分发类型\n",
    "    )\n",
    "]\n",
    "\n",
    "# 定义处理步骤的输出\n",
    "processing_outputs = [\n",
    "    ProcessingOutput(\n",
    "        output_name=\"train\",  # 输出的名称\n",
    "        s3_upload_mode=\"EndOfJob\",  # S3 上传模式\n",
    "        source=\"/opt/ml/processing/output/data/train\",  # 在处理容器内的源目录\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"validation\",  # 输出的名称\n",
    "        s3_upload_mode=\"EndOfJob\",  # S3 上传模式\n",
    "        source=\"/opt/ml/processing/output/data/validation\",  # 在处理容器内的源目录\n",
    "    ),\n",
    "    ProcessingOutput(\n",
    "        output_name=\"test\",  # 输出的名称\n",
    "        s3_upload_mode=\"EndOfJob\",  # S3 上传模式\n",
    "        source=\"/opt/ml/processing/output/data/test\",  # 在处理容器内的源目录\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 定义处理步骤\n",
    "processing_step = ProcessingStep(\n",
    "    name=\"Processing\",  # 处理步骤的名称\n",
    "    code=\"preprocess.py\",  # 执行的脚本\n",
    "    processor=processor,  # 使用的 processor\n",
    "    inputs=processing_inputs,  # 输入\n",
    "    outputs=processing_outputs,  # 输出\n",
    "    job_arguments=[  # 工作参数\n",
    "        \"--train-split-percentage\",\n",
    "        str(train_split_percentage.default_value),\n",
    "        \"--validation-split-percentage\",\n",
    "        str(validation_split_percentage.default_value),\n",
    "        \"--test-split-percentage\",\n",
    "        str(test_split_percentage.default_value),\n",
    "        \"--model-checkpoint\",\n",
    "        str(model_checkpoint.default_value),\n",
    "    ],\n",
    "    cache_config=cache_config  # 缓存配置\n",
    ")\n",
    "\n",
    "# 打印处理步骤的信息\n",
    "print(processing_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置 Training 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个字符串参数对象，名为 \"TrainInstanceType\"，默认值为 \"ml.c5.9xlarge\"。\n",
    "# 这个参数表示用于训练任务的 EC2 实例类型。\n",
    "train_instance_type = ParameterString(name=\"TrainInstanceType\", default_value=\"ml.c5.9xlarge\")\n",
    "\n",
    "# 创建一个整数参数对象，名为 \"TrainInstanceCount\"，默认值为 1。\n",
    "# 这个参数表示用于训练任务的 EC2 实例数量。\n",
    "train_instance_count = ParameterInteger(name=\"TrainInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个整数参数，名为 \"Epochs\"，默认值为1。\n",
    "# 这个参数表示模型训练时的迭代次数，也就是模型看过所有训练集数据的次数。\n",
    "epochs = ParameterInteger(name=\"Epochs\", default_value=1)\n",
    "\n",
    "# 创建一个浮点数参数，名为 \"LearningRate\"，默认值为0.00001。\n",
    "# 这个参数表示模型训练时的学习率，也就是模型在每次迭代时调整参数的速度。\n",
    "learning_rate = ParameterFloat(name=\"LearningRate\", default_value=0.00001)\n",
    "\n",
    "# 创建一个浮点数参数，名为 \"WeightDecay\"，默认值为0.01。\n",
    "# 这个参数表示模型训练时的权重衰减，用于防止模型过拟合。\n",
    "weight_decay = ParameterFloat(name=\"WeightDecay\", default_value=0.01)\n",
    "\n",
    "# 创建一个整数参数，名为 \"TrainBatchSize\"，默认值为4。\n",
    "# 这个参数表示在训练过程中一次性输入模型的数据数量。\n",
    "train_batch_size = ParameterInteger(name=\"TrainBatchSize\", default_value=4)\n",
    "\n",
    "# 创建一个整数参数，名为 \"ValidationBatchSize\"，默认值为4。\n",
    "# 这个参数表示在验证过程中一次性输入模型的数据数量。\n",
    "validation_batch_size = ParameterInteger(name=\"ValidationBatchSize\", default_value=4)\n",
    "\n",
    "# 创建一个整数参数，名为 \"TestBatchSize\"，默认值为4。\n",
    "# 这个参数表示在测试过程中一次性输入模型的数据数量。\n",
    "test_batch_size = ParameterInteger(name=\"TestBatchSize\", default_value=4)\n",
    "\n",
    "# 创建一个整数参数，名为 \"TrainVolumeSize\"，默认值为1024。\n",
    "# 这个参数表示训练任务使用的 EBS 卷的大小（单位：GB）。\n",
    "train_volume_size = ParameterInteger(name=\"TrainVolumeSize\", default_value=1024)\n",
    "\n",
    "# 创建一个字符串参数，名为 \"InputMode\"，默认值为 \"FastFile\"。\n",
    "# 这个参数表示输入模式，\"FastFile\" 表示使用 SageMaker FastFile 模式，这种模式可以更快地从 S3 下载数据。\n",
    "input_mode = ParameterString(name=\"InputMode\", default_value=\"FastFile\")\n",
    "\n",
    "# 创建一个浮点数参数，名为 \"TrainSamplePercentage\"，默认值为0.01。\n",
    "# 这个参数表示用于训练的数据的比例。\n",
    "train_sample_percentage = ParameterFloat(name=\"TrainSamplePercentage\", default_value=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置指标跟踪模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 metrics_definitions 的列表，该列表包含两个字典，每个字典定义了一个要从训练日志中提取的指标\n",
    "# 这些指标可以用来监控训练过程的进展\n",
    "\n",
    "# 创建一个列表，列表中的每个元素都是一个字典，这些字典定义了要从训练日志中提取的指标。\n",
    "metrics_definitions = [\n",
    "    # 第一个字典定义了一个名为 \"train:loss\" 的指标，这个指标的值将从训练日志中通过正则表达式 \"'train_loss': ([0-9\\\\.]+)\" 提取。\n",
    "    # 正则表达式 \"'train_loss': ([0-9\\\\.]+)\" 将匹配类似于 \"'train_loss': 0.1234\" 这样的文本，并提取出 0.1234 这样的数字作为 \"train:loss\" 指标的值。\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"'train_loss': ([0-9\\\\.]+)\"},\n",
    "    \n",
    "    # 第二个字典定义了一个名为 \"validation:loss\" 的指标，这个指标的值将从训练日志中通过正则表达式 \"'eval_loss': ([0-9\\\\.]+)\" 提取。\n",
    "    # 正则表达式 \"'eval_loss': ([0-9\\\\.]+)\" 将匹配类似于 \"'eval_loss': 0.1234\" 这样的文本，并提取出 0.1234 这样的数字作为 \"validation:loss\" 指标的值。\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"'eval_loss': ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建 Estimator\n",
    "\n",
    "我们配置Estimator和输入数据集。典型的训练脚本从输入通道加载数据，使用超参数配置训练，训练模型，并将模型保存到 `“model_dir”`，以便日后可以托管使用。\n",
    "\n",
    "我们还指定了保存模型的路径。\n",
    "\n",
    "请注意，也可以使用传递的 `train_instance_type` 参数并将其传递到管道中的其他地方。在这种情况下，`train_instance_type` 被传递到Estimator中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 sagemaker.pytorch 模块下的 PyTorch 类。这个类用于在 SageMaker 中配置和运行 PyTorch 训练任务。\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# 导入 uuid 模块，用于生成唯一的标识符。\n",
    "import uuid\n",
    "\n",
    "# 生成一个唯一的前缀，用于在 S3 中存储训练过程中的模型检查点。\n",
    "checkpoint_s3_prefix = \"checkpoints/{}\".format(str(uuid.uuid4()))\n",
    "\n",
    "# 构造 S3 URI，用于指定模型检查点存储的位置。\n",
    "checkpoint_s3_uri = \"s3://{}/{}/\".format(bucket, checkpoint_s3_prefix)\n",
    "\n",
    "# 创建一个 PyTorch estimator。这个 estimator 包含了训练任务的所有配置信息。\n",
    "estimator = PyTorch(\n",
    "    # \"train.py\" 是训练脚本的文件名，它包含模型训练的代码。\n",
    "    entry_point=\"train.py\",\n",
    "    \n",
    "    # \"src\" 是训练脚本所在的目录。\n",
    "    source_dir=\"src\",\n",
    "    \n",
    "    # role 是 AWS IAM 角色，SageMaker 将使用这个角色来访问训练数据和模型输出。\n",
    "    role=role,\n",
    "    \n",
    "    # 实例数量和实例类型是训练任务的硬件配置。\n",
    "    instance_count=train_instance_count,\n",
    "    instance_type=train_instance_type,\n",
    "    \n",
    "    # volume_size 是训练实例的磁盘大小（单位：GB）。\n",
    "    volume_size=train_volume_size,\n",
    "    \n",
    "    # py_version 和 framework_version 分别指定了训练任务中 Python 和 PyTorch 的版本。\n",
    "    py_version=\"py39\",\n",
    "    framework_version=\"1.13\",\n",
    "    \n",
    "    # hyperparameters 字典包含了训练任务的超参数。\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"weight_decay\": weight_decay,        \n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"validation_batch_size\": validation_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"model_checkpoint\": model_checkpoint,\n",
    "        \"train_sample_percentage\": train_sample_percentage,\n",
    "    },\n",
    "    \n",
    "    # input_mode 指定了数据输入模式，这里是 \"FastFile\"。\n",
    "    input_mode=input_mode,\n",
    "    \n",
    "    # metric_definitions 列表定义了要从训练日志中提取的指标。\n",
    "    metric_definitions=metrics_definitions,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置 Training 步骤\n",
    "\n",
    "最后，我们使用estimator实例构造一个 `TrainingStep` 以及之前的 `Properties` 的 `ProcessingStep`，在 `TrainingStep` 输入中用作输入，以及将在管道调用管道执行的执行代码。对于那些熟悉现有 Python SDK 的人来说，这与我们使用estimator实例构造一个的 `fit` 方法非常相似。\n",
    "\n",
    "特别是，我们将 `\"train\"`、`\"validation\"` 和 `\"test\"` 输出通道的 `S3Uri` 传递给 `TrainingStep`。工作流步骤的 `properties` 属性与描述调用的相应响应的对象模型相匹配。这些属性可以作为占位符值引用，并在运行时解析或填充。例如，`ProcessingStep` `properties`属性与 [describeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) 响应对象的对象模型相匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingStep(name='Train', display_name=None, description=None, step_type=<StepTypeEnum.TRAINING: 'Training'>, depends_on=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py:445: UserWarning: Profiling is enabled on the provided estimator. The default profiler rule includes a timestamp which will change each time the pipeline is upserted, causing cache misses. If profiling is not needed, set disable_profiler to True on the estimator.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# 导入 sagemaker.inputs 模块下的 TrainingInput 类。这个类用于在 SageMaker 中配置训练输入。\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "# 导入 sagemaker.workflow.steps 模块下的 TrainingStep 类。这个类用于在 SageMaker Pipelines 中定义训练步骤。\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "# 通过这个 training_step 对象，我们可以将训练步骤添加到 SageMaker Pipeline 中。\n",
    "# 在运行 Pipeline 时，会按照步骤定义的顺序执行每个步骤，每个步骤的输出会被用作后续步骤的输入。\n",
    "\n",
    "# 创建一个训练步骤。\n",
    "training_step = TrainingStep(\n",
    "    # \"Train\" 是这个训练步骤的名称。\n",
    "    name=\"Train\",\n",
    "    \n",
    "    # estimator 是前面创建的 PyTorch estimator，包含了训练任务的所有配置信息。\n",
    "    estimator=estimator,\n",
    "    \n",
    "    # inputs 是一个字典，定义了训练、验证和测试数据的位置。这些位置是由前面的处理步骤生成的。\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"validation\"].S3Output.S3Uri,\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=processing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "        ),\n",
    "    },\n",
    "    \n",
    "    # cache_config 是一个缓存配置对象，用于设置训练步骤的缓存策略。\n",
    "    cache_config=cache_config,\n",
    ")\n",
    "\n",
    "# 打印训练步骤对象。\n",
    "print(training_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评估步骤\n",
    "\n",
    "首先，我们开发了一个评估脚本，该脚本将在执行模型评估的处理步骤中指定。\n",
    "\n",
    "评估脚本 `evaluate_model_metrics.py` 将经过训练的模型和测试数据集作为输入，并生成一个包含评估指标的 JSON 文件。\n",
    "\n",
    "管道执行后，我们将检查生成的 `评估.json` 进行分析。\n",
    "\n",
    "评估脚本：\n",
    "\n",
    "* 部署模型\n",
    "* 读取测试数据\n",
    "* 根据测试数据进行大量预测\n",
    "* 生成评估报告\n",
    "* 将评估报告保存到评估目录中\n",
    "\n",
    "接下来，我们创建一个 `sklearnProcessor` 的实例，然后在 `ProcessingStep` 中使用它。\n",
    "\n",
    "请注意传递给处理器的 `processing_instance_type` 参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py3\n"
     ]
    }
   ],
   "source": [
    "# 导入 sagemaker.sklearn.processing 模块下的 SKLearnProcessor 类。这个类用于在 SageMaker 中配置和运行 Scikit-learn 代码。\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# 通过这个 evaluation_processor 对象，我们可以调用其 run 方法来执行 Scikit-learn 代码\n",
    "# 或者将其添加到 ProcessingStep 中，作为 SageMaker Pipeline 的一部分进行执行\n",
    "\n",
    "# 创建一个 SKLearnProcessor 对象。\n",
    "evaluation_processor = SKLearnProcessor(\n",
    "    # 指定 Scikit-learn 的版本。\n",
    "    framework_version=\"0.23-1\",\n",
    "    \n",
    "    # role 是 AWS IAM 角色，SageMaker 将使用这个角色来访问数据和存储处理结果。\n",
    "    role=role,\n",
    "    \n",
    "    # instance_type 和 instance_count 是处理任务的硬件配置。\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    \n",
    "    # env 是一个字典，包含了传递给处理任务的环境变量。\n",
    "    env={\"AWS_DEFAULT_REGION\": region},\n",
    "    \n",
    "    # max_runtime_in_seconds 是处理任务的最长运行时间（单位：秒）。\n",
    "    max_runtime_in_seconds=432000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` ^^ above ^^._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用processor实例来构造 `ProcessingStep`，以及输入和输出通道以及将在管道调用管道执行时执行的代码。对于那些熟悉现有 Python SDK 的人来说，这与处理器实例的 `run` 方法非常相似。\n",
    "\n",
    "`TrainingStep` 和 `ProcessingStep` 的 `properties` 属性分别与 [describeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) 和 [describeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) 响应对象的对象模型相匹配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 sagemaker.workflow.properties 模块下的 PropertyFile 类。这个类用于在 SageMaker Pipeline 中定义属性文件。\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "# evaluation_report 对象可以被添加到 ProcessingStep 中，作为其 property_files 参数的一部分。\n",
    "# 在运行 Pipeline 时，ProcessingStep 会将指定路径的文件解析为一组属性，并将其作为输出提供给后续步骤\n",
    "# evaluation_report 对象表示一个名为 \"EvaluationReport\" 的属性文件，这个文件由某个步骤生成并存储在 \"evaluation.json\" 文件中。\n",
    "# 这个文件中可能包含了模型的各种评估指标，如精度、召回率等。\n",
    "# 在 Pipeline 运行时，后续步骤可以通过 \"metrics\" 这个名称来引用这些指标。\n",
    "\n",
    "# 创建一个 PropertyFile 对象。\n",
    "evaluation_report = PropertyFile(\n",
    "    # \"EvaluationReport\" 是这个属性文件的名称。\n",
    "    name=\"EvaluationReport\",\n",
    "    \n",
    "    # \"metrics\" 是输出的名称，这个名称将用于在后续步骤中引用这个输出。\n",
    "    output_name=\"metrics\",\n",
    "    \n",
    "    # \"evaluation.json\" 是属性文件在处理容器中的路径。\n",
    "    path=\"evaluation.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个处理步骤对象。\n",
    "evaluation_step = ProcessingStep(\n",
    "    # \"EvaluateModel\" 是这个处理步骤的名称。\n",
    "    name=\"EvaluateModel\",\n",
    "    \n",
    "    # processor 是前面创建的 SKLearnProcessor 对象，包含了处理任务的所有配置信息。\n",
    "    processor=evaluation_processor,\n",
    "    \n",
    "    # \"evaluate_model_metrics.py\" 是要运行的 Python 脚本的路径。这个脚本应该包含模型评估的代码。\n",
    "    code=\"evaluate_model_metrics.py\",\n",
    "    \n",
    "    # inputs 是一个列表，定义了处理任务的输入数据的位置和在容器中的目标路径。\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            # source 是输入数据的 S3 路径。这里使用了前面的训练步骤的输出模型作为输入。\n",
    "            source=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            \n",
    "            # destination 是在容器中的目标路径，输入数据将被下载到这个路径。\n",
    "            destination=\"/opt/ml/processing/input/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            # source 是输入数据的 S3 路径。这里使用了前面的处理步骤的测试数据作为输入。\n",
    "            source=processing_step.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            \n",
    "            # destination 是在容器中的目标路径，输入数据将被下载到这个路径。\n",
    "            destination=\"/opt/ml/processing/input/data\"\n",
    "        ),\n",
    "    ],\n",
    "    \n",
    "    # outputs 是一个列表，定义了处理任务的输出数据的来源和存储位置。\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            # source 是在容器中的来源路径，处理结果将从这个路径收集并上传到 S3。\n",
    "            source=\"/opt/ml/processing/output/metrics/\",\n",
    "            \n",
    "            # output_name 是输出的名称，这个名称将用于在后续步骤中引用这个输出。\n",
    "            output_name=\"metrics\",\n",
    "            \n",
    "            # s3_upload_mode 是数据上传到 S3 的模式。\"EndOfJob\" 表示在处理任务结束时上传数据。\n",
    "            s3_upload_mode=\"EndOfJob\"\n",
    "        ),\n",
    "    ],\n",
    "    \n",
    "    # property_files 是一个列表，定义了处理任务输出的属性文件。这些文件中的内容将被解析为一组属性，并可以在后续步骤中引用。\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.model_metrics.ModelMetrics object at 0x7f6488a56bd0>\n"
     ]
    }
   ],
   "source": [
    "# 导入 SageMaker 库中的 MetricsSource 和 ModelMetrics 类\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics\n",
    "\n",
    "# 使用 ModelMetrics 类创建一个新的 model_metrics 对象\n",
    "model_metrics = ModelMetrics(\n",
    "    # 指定模型统计信息来源\n",
    "    model_statistics=MetricsSource(\n",
    "        # 使用 format 方法构建 s3_uri，该 URI 指向评估步骤输出的结果文件的位置\n",
    "        # 其中，evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        # 是从处理步骤的输出配置中获取第一个输出的 S3Uri 的值\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            evaluation_step.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        # 指定内容类型为 JSON\n",
    "        content_type=\"application/json\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# 打印 model_metrics 对象\n",
    "print(model_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注册模型步骤\n",
    "\n",
    "![](img/pipeline-5.png)\n",
    "\n",
    "我们使用用于训练步骤的估计器实例来构造 `RegisterModel` 的实例。在管道中执行 `registerModel` 的结果是一个模型包。模型包是一种可重复使用的模型工件抽象，它打包了推理所需的所有要素。它主要由定义要使用的推理图像的推理规范以及可选的模型权重位置组成。\n",
    "\n",
    "模型包组是模型包的集合。您可以针对特定的机器学习业务问题创建模型包组，并且可以继续向其中添加版本/模型包。通常，我们希望客户为 SageMaker 工作流管道创建 ModelPackageGroup，这样他们就可以在每次运行工作流管道时继续向该组添加版本/模型包。\n",
    "\n",
    "对于那些熟悉现有 Python SDK 的人来说，`registerModel` 的构造与estimator实例的 `register` 方法非常相似。\n",
    "\n",
    "特别是，我们从 `TrainingStep`、`step_train` 属性中传入 `s3modelArtifacts`。`TrainingStep` `properties`属性与 [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) 响应对象的对象模型相匹配。\n",
    "\n",
    "值得注意的是，我们提供了一个特定的模型包组名称，稍后将在模型注册表和 CI/CD 工作中使用该名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 ParameterString 类，创建一个名为 \"ModelApprovalStatus\" 的参数，\n",
    "# 默认值为 \"PendingManualApproval\"。这将用于设定模型批准的状态。\n",
    "model_approval_status = ParameterString(name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\")\n",
    "\n",
    "# 导入 ParameterString 类，创建一个名为 \"DeployInstanceType\" 的参数，\n",
    "# 默认值为 \"ml.m5.4xlarge\"。这将用于设定部署模型时使用的实例类型。\n",
    "deploy_instance_type = ParameterString(name=\"DeployInstanceType\", default_value=\"ml.m5.4xlarge\")\n",
    "\n",
    "# 导入 ParameterInteger 类，创建一个名为 \"DeployInstanceCount\" 的参数，\n",
    "# 默认值为 1。这将用于设定部署模型时使用的实例数量。\n",
    "deploy_instance_count = ParameterInteger(name=\"DeployInstanceCount\", default_value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarization-1694913823\n"
     ]
    }
   ],
   "source": [
    "# 导入 Python 的 time 模块\n",
    "import time\n",
    "\n",
    "# 使用 time 模块的 time 函数获取当前的 Unix 时间戳（以秒为单位），并将其转换为整数\n",
    "timestamp = int(time.time())\n",
    "\n",
    "# 使用 f-string（格式化字符串字面值）创建一个名为 \"Summarization-{timestamp}\" 的模型包组名，\n",
    "# 其中 {timestamp} 会被上一步获得的时间戳替换。\n",
    "model_package_group_name = f\"Summarization-{timestamp}\"\n",
    "\n",
    "# 打印 model_package_group_name\n",
    "print(model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.workflow.utilities:The input argument instance_type of function (sagemaker.image_uris.retrieve) is a pipeline variable (<class 'sagemaker.workflow.parameters.ParameterString'>), which is not allowed. The default_value of this Parameter object will be used to override it. Please make sure the default_value is valid.\n",
      "INFO:sagemaker.image_uris:Defaulting to only available Python version: py39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-inference:1.13-cpu-py39\n"
     ]
    }
   ],
   "source": [
    "# 使用 sagemaker.image_uris.retrieve 函数获取适用于推理的 PyTorch 框架的 Docker 镜像 URI\n",
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    # 指定机器学习框架为 \"pytorch\"\n",
    "    framework=\"pytorch\",\n",
    "    # 指定 AWS 区域\n",
    "    region=region,\n",
    "    # 指定框架版本为 \"1.13\"\n",
    "    version=\"1.13\",\n",
    "    # 指定实例类型，值从之前定义的 deploy_instance_type 参数获取\n",
    "    instance_type=deploy_instance_type,\n",
    "    # 指定镜像作用范围为 \"inference\"\n",
    "    image_scope=\"inference\",\n",
    ")\n",
    "\n",
    "# 打印 inference_image_uri\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个 RegisterModel 步骤，该步骤将在 SageMaker 工作流中执行，用于将训练好的模型注册到 SageMaker 模型注册表中，以便后续进行部署或其他操作。\n",
    "\n",
    "# 导入 SageMaker 工作流的 RegisterModel 类\n",
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# 创建一个 RegisterModel 实例，用于在 SageMaker 模型注册表中注册模型\n",
    "register_step = RegisterModel(\n",
    "    # 为模型指定一个名称 \"Summarization\"\n",
    "    name=\"Summarization\",\n",
    "    # 指定一个估算器对象，通常包含了训练作业的配置\n",
    "    estimator=estimator,\n",
    "    # 指定用于推理的 Docker 镜像 URI，这里我们需要明确指定，因为默认情况下会使用训练镜像\n",
    "    image_uri=inference_image_uri,\n",
    "    # 指定模型数据的 S3 URI，这里从训练步骤的属性中获取\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    # 指定模型可以接受的输入数据类型，这里为 \"application/jsonlines\"\n",
    "    content_types=[\"application/jsonlines\"],\n",
    "    # 指定模型可以返回的响应类型，这里为 \"application/jsonlines\"\n",
    "    response_types=[\"application/jsonlines\"],\n",
    "    # 指定可用于推理的实例类型，这里从之前定义的 deploy_instance_type 参数获取\n",
    "    inference_instances=[deploy_instance_type],\n",
    "    # 指定可用于转换作业的实例类型，这里从之前定义的 deploy_instance_type 参数获取\n",
    "    transform_instances=[deploy_instance_type],\n",
    "    # 指定模型包组的名称，这里从之前生成的 model_package_group_name 变量获取\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    # 指定模型的批准状态，这里从之前定义的 model_approval_status 参数获取\n",
    "    approval_status=model_approval_status,\n",
    "    # 指定模型的指标，这里从之前创建的 model_metrics 对象获取\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为部署步骤创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 SageMaker 的 Model 类\n",
    "from sagemaker.model import Model\n",
    "\n",
    "# 使用 f-string（格式化字符串字面值）创建一个名为 \"model-{timestamp}\" 的模型名，\n",
    "# 其中 {timestamp} 会被上一步获得的时间戳替换。\n",
    "model_name = \"model-{}\".format(timestamp)\n",
    "\n",
    "# 使用 Model 类创建一个新的 model 对象\n",
    "model = Model(\n",
    "    # 指定模型的名称\n",
    "    name=model_name,\n",
    "    # 指定用于推理的 Docker 镜像 URI\n",
    "    image_uri=inference_image_uri,\n",
    "    # 指定模型数据的 S3 URI，这里从训练步骤的属性中获取\n",
    "    model_data=training_step.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    # 指定 SageMaker 会话，这通常包含了 SageMaker 运行的配置信息\n",
    "    sagemaker_session=sess,\n",
    "    # 指定 IAM 角色，SageMaker 会使用这个角色来执行训练和部署任务\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 SageMaker 的 CreateModelInput 类\n",
    "from sagemaker.inputs import CreateModelInput\n",
    "\n",
    "# 使用 CreateModelInput 类创建一个新的 create_inputs 对象\n",
    "create_inputs = CreateModelInput(\n",
    "    # 指定实例类型，这通常是预定于模型部署的实例类型，\n",
    "    # 这里从之前定义的 deploy_instance_type 参数获取\n",
    "    instance_type=deploy_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入 SageMaker 工作流的 CreateModelStep 类\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "# 创建一个 CreateModelStep 实例，用于在 SageMaker 工作流中创建模型\n",
    "create_step = CreateModelStep(\n",
    "    # 为创建模型的步骤指定一个名称 \"CreateModel\"\n",
    "    name=\"CreateModel\",\n",
    "    # 指定要创建的模型，这里从之前创建的 model 对象获取\n",
    "    model=model,\n",
    "    # 指定创建模型时的输入参数，这里从之前创建的 create_inputs 对象获取\n",
    "    inputs=create_inputs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 条件部署步骤\n",
    "![](img/pipeline-6.png)\n",
    "\n",
    "最后，我们只想在模型的指标（由我们的评估步骤确定）超过给定阈值时才注册此模型。`ConditionStep` 允许管道支持基于步骤属性的条件在管道 DAG 中进行条件执行。\n",
    "\n",
    "下面，我们执行以下操作：\n",
    "* 根据评估步骤输出中找到的评估指标定义一个条件\n",
    "* 在 `ConditionStep` 中使用条件列表中的条件\n",
    "* 将 `registerModel` 步骤集合传递到 `ConditionStep` 的 `if_steps` 中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.deprecations:The class JsonGet has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# 导入 SageMaker 工作流的条件和条件步骤类\n",
    "from sagemaker.workflow.conditions import ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "from sagemaker.workflow.parameters import ParameterFloat\n",
    "\n",
    "# 创建一个名为 \"MinRouge1Value\" 的浮点参数，其默认值为 0.005\n",
    "min_rouge_value = ParameterFloat(name=\"MinRouge1Value\", default_value=0.005)\n",
    "\n",
    "# 创建一个条件对象，该条件检查 evaluation_step 的 \"metrics.eval_rouge1.value\" 是否大于或等于 min_rouge_value\n",
    "min_rouge_condition = ConditionGreaterThanOrEqualTo(\n",
    "    # 从 evaluation_step 的 evaluation_report 属性文件中获取 \"metrics.eval_rouge1.value\"\n",
    "    left=JsonGet(\n",
    "        step=evaluation_step,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"metrics.eval_rouge1.value\",\n",
    "    ),\n",
    "    # 指定右边的值，这里是 min_rouge_value 参数\n",
    "    right=min_rouge_value,\n",
    ")\n",
    "\n",
    "# 创建一个条件步骤，如果条件满足，则执行 register_step 和 create_step，否则，结束流程\n",
    "min_rouge_condition_step = ConditionStep(\n",
    "    # 为条件步骤指定一个名称 \"EvaluationCondition\"\n",
    "    name=\"EvaluationCondition\",\n",
    "    # 指定条件，这里是上面创建的 min_rouge_condition\n",
    "    conditions=[min_rouge_condition],\n",
    "    # 如果条件满足，则执行的步骤，这里是 register_step 和 create_step\n",
    "    if_steps=[register_step, create_step],\n",
    "    # 如果条件不满足，则执行的步骤，这里为空，表示结束流程\n",
    "    else_steps=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义由参数、步骤和条件组成的Pipeline\n",
    "\n",
    "让我们把它全部绑定到一个工作流程Pipeline中，这样我们就可以执行它，甚至可以安排它。\n",
    "\n",
    "管道需要 `name`, `parameters` 和 `steps`。在 `(account, region)` 对中，名称必须是唯一的，因此我们在名称上加上时间戳。\n",
    "\n",
    "\n",
    "注意：\n",
    "\n",
    "* 定义中使用的所有参数都必须存在。\n",
    "* 传递到管道中的步骤不必按执行顺序排列。SageMaker Workflow 服务将在执行完成的步骤中解析 _data 依赖关系_ DAG。\n",
    "* 对于工作流步骤列表或单个条件步骤 if/else 列表，步骤必须是唯一的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将Pipeline提交给 SageMaker 进行执行 \n",
    "\n",
    "让我们向工作流服务提交我们的Pipeline定义。工作流服务将使用传入的角色来创建步骤中定义的所有作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] You already have created 1 pipeline with name dialogue-summary-pipeline-1694260461.\n",
      "****************************************************************************************************************\n",
      "You have already create a pipeline with the name dialogue-summary-pipeline-1694260461. This is OK. Please continue to the next cell.\n",
      "****************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# 从sagemaker.workflow.pipeline导入Pipeline模块\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# 初始化现有管道的数量为0\n",
    "existing_pipelines = 0\n",
    "\n",
    "# 调用sm.list_pipelines()方法来列出所有的管道，按管道名前缀排序，并且是降序排序\n",
    "existing_pipelines_response = sm.list_pipelines(\n",
    "    PipelineNamePrefix=pipeline_name,\n",
    "    SortOrder=\"Descending\",\n",
    ")\n",
    "\n",
    "# 检查返回的响应中是否包含\"PipelineSummaries\"这个关键字\n",
    "if \"PipelineSummaries\" in existing_pipelines_response.keys():\n",
    "    # 如果\"PipelineSummaries\"的长度大于0，说明已经有现有的管道\n",
    "    if len(existing_pipelines_response[\"PipelineSummaries\"]) > 0:\n",
    "        existing_pipelines = existing_pipelines + 1\n",
    "        # 打印出已经创建的管道的数量和名称\n",
    "        print(\"[INFO] You already have created {} pipeline with name {}.\".format(existing_pipelines, pipeline_name))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# 如果没有已经存在的管道，就创建一个新的管道\n",
    "if existing_pipelines == 0:  \n",
    "    # 使用Pipeline类创建一个新的管道，配置其名称、参数和步骤等信息\n",
    "    pipeline = Pipeline(\n",
    "        name=pipeline_name,\n",
    "        parameters=[\n",
    "            input_data,\n",
    "            processing_instance_count,\n",
    "            processing_instance_type,\n",
    "            train_split_percentage,\n",
    "            validation_split_percentage,\n",
    "            test_split_percentage,\n",
    "            train_instance_type,\n",
    "            train_instance_count,\n",
    "            epochs,\n",
    "            learning_rate,\n",
    "            weight_decay,\n",
    "            train_sample_percentage,\n",
    "            train_batch_size,\n",
    "            validation_batch_size,\n",
    "            test_batch_size,\n",
    "            train_volume_size,\n",
    "            input_mode,\n",
    "            min_rouge_value,\n",
    "            model_approval_status,\n",
    "            deploy_instance_type,\n",
    "            deploy_instance_count,\n",
    "            model_checkpoint.to_string(),\n",
    "        ],\n",
    "        steps=[processing_step, training_step, evaluation_step, min_rouge_condition_step],\n",
    "        sagemaker_session=sess,\n",
    "    )\n",
    "\n",
    "    # 使用upsert方法将新创建的管道更新或插入到SageMaker的管道列表中\n",
    "    pipeline.upsert(role_arn=role)[\"PipelineArn\"]\n",
    "    # 打印出已经创建的管道的名称\n",
    "    print(\"Created pipeline with name {}\".format(pipeline_name))\n",
    "else:\n",
    "    # 如果已经存在一个同名的管道，就打印出提示信息\n",
    "    print(\n",
    "        \"****************************************************************************************************************\"\n",
    "    )\n",
    "    print(\n",
    "        \"You have already create a pipeline with the name {}. This is OK. Please continue to the next cell.\".format(\n",
    "            pipeline_name\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"****************************************************************************************************************\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` ^^ above ^^._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 启动 Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started pipeline dialogue-summary-pipeline-1694260461.  Ignore any warnings above.\n",
      "arn:aws:sagemaker:us-east-1:941797585610:pipeline/dialogue-summary-pipeline-1694260461/execution/jf2hsti28rlc\n"
     ]
    }
   ],
   "source": [
    "# 初始化正在运行的执行数量和已完成的执行数量均为0\n",
    "running_executions = 0\n",
    "completed_executions = 0\n",
    "\n",
    "# 如果存在管道\n",
    "if existing_pipelines > 0:\n",
    "    # 调用sm.list_pipeline_executions()方法列出所有管道执行，按执行名前缀排序，并且是降序排序\n",
    "    existing_pipeline_executions_response = sm.list_pipeline_executions(\n",
    "        PipelineName=pipeline_name,\n",
    "        SortOrder=\"Descending\",\n",
    "    )\n",
    "\n",
    "    # 检查返回的响应中是否包含\"PipelineExecutionSummaries\"这个关键字\n",
    "    if \"PipelineExecutionSummaries\" in existing_pipeline_executions_response.keys():\n",
    "        # 如果\"PipelineExecutionSummaries\"的长度大于0，说明已经有现有的管道执行\n",
    "        if len(existing_pipeline_executions_response[\"PipelineExecutionSummaries\"]) > 0:\n",
    "            execution = existing_pipeline_executions_response[\"PipelineExecutionSummaries\"][0]\n",
    "            # 检查执行状态\n",
    "            if \"PipelineExecutionStatus\" in execution:\n",
    "                # 如果执行状态为\"Executing\"，则该执行正在运行\n",
    "                if execution[\"PipelineExecutionStatus\"] == \"Executing\":\n",
    "                    running_executions = running_executions + 1\n",
    "                else:\n",
    "                    # 否则，该执行已完成\n",
    "                    completed_executions = completed_executions + 1\n",
    "\n",
    "            # 打印出当前正在运行的执行数量和已完成的执行数量\n",
    "            print(\n",
    "                \"[INFO] You have {} Pipeline execution(s) currently running and {} execution(s) completed.\".format(\n",
    "                    running_executions, completed_executions\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        pass\n",
    "else:\n",
    "    pass\n",
    "\n",
    "# 如果没有正在运行的执行，就启动一个新的执行\n",
    "if running_executions == 0:  \n",
    "    # 使用start()方法启动管道执行\n",
    "    execution = pipeline.start()\n",
    "    running_executions = running_executions + 1\n",
    "    # 打印出已经启动的管道的名称和执行的ARN\n",
    "    print(\"Started pipeline {}.  Ignore any warnings above.\".format(pipeline_name))\n",
    "    print(execution.arn)\n",
    "else:\n",
    "    # 如果已经存在一个正在运行的执行，就打印出提示信息\n",
    "    print(\n",
    "        \"********************************************************************************************************************\"\n",
    "    )\n",
    "    print(\n",
    "        \"You have already launched {} pipeline execution(s).  This is OK.  Please continue to see the next cell.\".format(\n",
    "            running_executions\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"********************************************************************************************************************\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Ignore any `WARNING` ^^ above ^^._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 等待Pipeline完成\n",
    "\n",
    "### _This next cell takes about 40 mins.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "# 使用 %%time 魔法命令计算代码块的运行时间\n",
    "%%time\n",
    "\n",
    "# 导入所需的模块\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "# 调用sm.list_pipeline_executions()方法列出所有管道执行，并获取第一个执行的状态\n",
    "executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "# 打印出执行的状态\n",
    "print(pipeline_execution_status)\n",
    "\n",
    "# 当执行的状态是\"Executing\"（正在执行）时，继续检查执行状态\n",
    "while pipeline_execution_status == \"Executing\":\n",
    "    try:\n",
    "        # 再次调用sm.list_pipeline_executions()方法获取执行的状态\n",
    "        executions_response = sm.list_pipeline_executions(PipelineName=pipeline_name)[\"PipelineExecutionSummaries\"]\n",
    "        pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "    except Exception as e:\n",
    "        # 如果发生异常，打印\"Please wait...\"并等待30秒后再次检查\n",
    "        print(\"Please wait...\")\n",
    "        time.sleep(30)\n",
    "\n",
    "# 打印出执行的响应\n",
    "pprint(executions_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Wait for the Pipeline ^^ Above ^^ to Complete_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 列出完成后的Pipeline执行步骤和状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从执行响应中获取管道执行的状态和ARN\n",
    "pipeline_execution_status = executions_response[0][\"PipelineExecutionStatus\"]\n",
    "pipeline_execution_arn = executions_response[0][\"PipelineExecutionArn\"]\n",
    "\n",
    "# 打印出管道执行的状态和ARN\n",
    "print(\"Pipeline execution status {}\".format(pipeline_execution_status))\n",
    "print(\"Pipeline execution arn {}\".format(pipeline_execution_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入pprint库，用于更优美的打印输出\n",
    "from pprint import pprint\n",
    "\n",
    "# 调用sm.list_pipeline_execution_steps()方法，列出指定管道执行的所有步骤\n",
    "steps = sm.list_pipeline_execution_steps(PipelineExecutionArn=pipeline_execution_arn)\n",
    "\n",
    "# 使用pprint打印出所有步骤的详细信息\n",
    "pprint(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 列出管道生成的所有Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化处理任务的名称和训练任务的名称为None\n",
    "processing_job_name = None\n",
    "training_job_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入需要的模块\n",
    "import time\n",
    "from sagemaker.lineage.visualizer import LineageTableVisualizer\n",
    "\n",
    "# 使用sagemaker的会话创建LineageTableVisualizer对象，用于显示管道执行的各个步骤与其输出的关系\n",
    "viz = LineageTableVisualizer(sagemaker.session.Session())\n",
    "\n",
    "# 逆序遍历管道执行的所有步骤\n",
    "for execution_step in reversed(steps[\"PipelineExecutionSteps\"]):\n",
    "    # 打印出每个步骤的详细信息\n",
    "    print(execution_step)\n",
    "    # 检查步骤名称是否为\"Processing\"\n",
    "    if execution_step[\"StepName\"] == \"Processing\":\n",
    "        # 如果是\"Processing\"步骤，获取处理任务的ARN，并解析出处理任务的名称\n",
    "        processing_job_name = execution_step[\"Metadata\"][\"ProcessingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        # 打印出处理任务的名称\n",
    "        print(processing_job_name)\n",
    "        # 显示处理任务的血统表格\n",
    "        display(viz.show(processing_job_name=processing_job_name))\n",
    "    # 检查步骤名称是否为\"Train\"\n",
    "    elif execution_step[\"StepName\"] == \"Train\":\n",
    "        # 如果是\"Train\"步骤，获取训练任务的ARN，并解析出训练任务的名称\n",
    "        training_job_name = execution_step[\"Metadata\"][\"TrainingJob\"][\"Arn\"].split(\"/\")[-1]\n",
    "        # 打印出训练任务的名称\n",
    "        print(training_job_name)\n",
    "        # 显示训练任务的血统表格\n",
    "        display(viz.show(training_job_name=training_job_name))\n",
    "    else:\n",
    "        # 如果是其他步骤，直接显示该步骤的血统表格\n",
    "        display(viz.show(pipeline_execution_step=execution_step))\n",
    "        # 等待5秒，然后处理下一个步骤\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Execution Run as Trial to Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '-aws-processing-job' 是 ProcessingJob 默认分配的名称\n",
    "# 格式化字符串，将处理任务的名称与'-aws-processing-job'拼接起来\n",
    "processing_job_tc = \"{}-aws-processing-job\".format(processing_job_name)\n",
    "# 打印出拼接后的处理任务名称\n",
    "print(processing_job_tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 sm.associate_trial_component 方法将处理任务与试验关联起来\n",
    "response = sm.associate_trial_component(TrialComponentName=processing_job_tc, TrialName=pipeline_trial_name)\n",
    "\n",
    "# 这段脚本的主要功能是关联处理任务和试验。在Amazon SageMaker中，一个试验可以包含一个或多个试验组件（例如处理任务、训练任务等）。\n",
    "# 通过调用sm.associate_trial_component方法，可以将处理任务（作为试验组件）与指定的试验关联起来。\n",
    "# 这样，当查看试验的详细信息时，就可以看到该试验包含哪些试验组件，以及每个组件的详细信息和结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '-aws-training-job' 是 TrainingJob 默认分配的名称\n",
    "# 格式化字符串，将训练任务的名称与'-aws-training-job'拼接起来\n",
    "training_job_tc = \"{}-aws-training-job\".format(training_job_name)\n",
    "# 打印出拼接后的训练任务名称\n",
    "print(training_job_tc)\n",
    "\n",
    "# 这段脚本的主要功能是创建一个新的字符串training_job_tc，它是由训练任务的名称和字符串\"-aws-training-job\"拼接而成。\n",
    "# 在Amazon SageMaker中，训练任务的名称通常以\"-aws-training-job\"为后缀。\n",
    "# 这个新的字符串training_job_tc可能会被用作进一步查询训练任务的详细信息或结果的标识符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用 sm.associate_trial_component 方法将训练任务与试验关联起来\n",
    "response = sm.associate_trial_component(TrialComponentName=training_job_tc, TrialName=pipeline_trial_name)\n",
    "\n",
    "# 这段脚本的主要功能是关联训练任务和试验。\n",
    "# 在Amazon SageMaker中，一个试验可以包含一个或多个试验组件（例如处理任务、训练任务等）。\n",
    "# 通过调用sm.associate_trial_component方法，您可以将训练任务（作为试验组件）与指定的试验关联起来。\n",
    "# 这样，当您查看试验的详细信息时，就可以看到该试验包含哪些试验组件，以及每个组件的详细信息和结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
