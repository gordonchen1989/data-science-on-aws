{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Amazon SageMaker Processing Job进行特征转换\n",
    "\n",
    "通常，一个机器学习（ML）过程包括几个步骤。首先，通过各种ETL任务收集数据，然后对数据进行预处理，通过采用标准技术或先前的知识对数据集进行特征化，最后使用算法训练一个ML模型。\n",
    "\n",
    "我们可以使用分布式数据处理框架，如Scikit-Learn、Spark、Ray等，对数据集进行预处理，以便为训练做好准备。在这个笔记本中，我们将使用Amazon SageMaker Processing，并利用HuggingFace在托管的SageMaker环境中运行我们的处理工作负载。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name='1'></a>\n",
    "## Set up Kernel and Required Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, check that the correct kernel is chosen.\n",
    "\n",
    "<img src=\"img/kernel_set_up.png\" width=\"300\"/>\n",
    "\n",
    "You can click on that to see and check the details of the image, kernel, and instance type.\n",
    "\n",
    "<img src=\"img/w3_kernel_and_instance_type.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE:  THIS NOTEBOOK WILL TAKE A 5-10 MINUTES TO COMPLETE.\n",
    "\n",
    "# PLEASE BE PATIENT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. 设置环境\n",
    "2. 设置输入数据\n",
    "3. 设置输出数据\n",
    "4. 为运行处理作业构建一个Scikit-Learn容器\n",
    "5. 使用Amazon SageMaker运行Processing job\n",
    "6. 检查处理后的输出数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置环境\n",
    "\n",
    "开始以下内容：\n",
    "\n",
    "* 用于训练和模型数据的S3存储桶和前缀。使用Amazon SageMaker会话指定的默认存储桶。\n",
    "* 用于给处理和训练提供数据集访问权限的IAM角色ARN。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入 Amazon SageMaker 和 boto3 库\n",
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# 创建一个 SageMaker 会话\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# 获取当前 SageMaker 执行角色的 Amazon Resource Name（ARN），该角色决定了 SageMaker 可以对哪些 AWS 资源进行访问\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# 获取当前 SageMaker 会话的默认 S3 存储桶名\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# 获取当前 boto3 会话的区域名，这决定了你的 AWS 服务在哪个地理位置被部署\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# 导入 botocore 库的 config 模块，它提供了设置 AWS 服务客户端的配置选项\n",
    "import botocore.config\n",
    "\n",
    "# 创建一个 botocore 的 Config 对象，设置 user_agent_extra 参数为 'dsoaws/2.0'，这将在每次 AWS 请求的 User-Agent 头部添加这个字符串\n",
    "config = botocore.config.Config(\n",
    "    user_agent_extra='dsoaws/2.0'\n",
    ")\n",
    "\n",
    "# 创建一个指向 Amazon SageMaker 的 boto3 客户端，设置服务名为 \"sagemaker\"，区域名为前面获取的 region，配置为前面创建的 config\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", \n",
    "                            region_name=region, \n",
    "                            config=config)\n",
    "\n",
    "# 创建一个指向 Amazon S3 的 boto3 客户端，设置服务名为 \"s3\"，区域名为前面获取的 region，配置为前面创建的 config\n",
    "s3 = boto3.Session().client(service_name=\"s3\", \n",
    "                            region_name=region,\n",
    "                            config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 设置输入数据的S3 URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-05 03:06:01    6544107 dialogsum-1.csv\n",
      "2023-09-05 03:06:01    6572423 dialogsum-2.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'raw_input_data_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载其他变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r model_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_checkpoint\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the PREPARE section before you continue.\")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google/flan-t5-base\n"
     ]
    }
   ],
   "source": [
    "print(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Amazon SageMaker运行处理作业Processing Job\n",
    "\n",
    "接下来，使用Amazon SageMaker Python SDK提交一个使用我们自定义python脚本的处理作业。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看处理脚本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# 导入 subprocess 模块，该模块可以用来创建新的进程，并连接到其输入/输出/错误管道，获取返回值等\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 导入 sys 模块，该模块提供对 Python 解释器使用或维护的一些变量的访问\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 导入 json 模块，该模块提供了 JSON 数据解析的方法\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 导入 argparse 模块，该模块提供了创建命令行参数和选项的方法\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 使用 subprocess 模块的 check_call 方法运行 pip 安装命令，安装特定版本的 transformers、datasets 和 torch 库\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# sys.executable 是 Python 解释器的路径，\"-m\" 是一个命令行选项，表示后面的字符串应作为模块名来执行\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "subprocess.check_call([sys.executable, \u001b[33m\"\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtransformers==4.26.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mdatasets==2.9.0\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mtorch==1.13.1\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 从 transformers 库中导入 AutoTokenizer 类，该类可以自动加载预训练的分词器\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m AutoTokenizer\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 从 datasets 库中导入 load_dataset 函数和 DatasetDict 类，load_dataset 函数可以加载各种 NLP 数据集，DatasetDict 类可以管理多个数据集\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mdatasets\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m load_dataset, DatasetDict\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 导入 os 模块，该模块提供了大量的函数来处理文件和目录\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 导入 time 模块，该模块提供了时间相关的函数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 定义一个 transform_dataset 函数，参数包括输入数据的路径、输出数据的路径、预训练模型名，以及训练集、测试集和验证集的划分比率\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtransform_dataset\u001b[39;49;00m(input_data,\u001b[37m\u001b[39;49;00m\n",
      "                      output_data,\u001b[37m\u001b[39;49;00m\n",
      "                      huggingface_model_name,\u001b[37m\u001b[39;49;00m\n",
      "                      train_split_percentage,\u001b[37m\u001b[39;49;00m\n",
      "                      test_split_percentage,\u001b[37m\u001b[39;49;00m\n",
      "                      validation_split_percentage,\u001b[37m\u001b[39;49;00m\n",
      "                      ):\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 加载原始数据集\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    dataset = load_dataset(input_data)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m数据集已从路径 \u001b[39;49;00m\u001b[33m{\u001b[39;49;00minput_data\u001b[33m}\u001b[39;49;00m\u001b[33m 加载\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdataset\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 加载分词器\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m正在加载模型 \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mhuggingface_model_name\u001b[33m}\u001b[39;49;00m\u001b[33m 的分词器\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenizer = AutoTokenizer.from_pretrained(huggingface_model_name)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 对数据集进行训练集、测试集和验证集的划分\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_testvalid = dataset[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].train_test_split(\u001b[34m1\u001b[39;49;00m - train_split_percentage, seed=\u001b[34m1234\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    test_valid = train_testvalid[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].train_test_split(test_split_percentage / (validation_split_percentage + test_split_percentage), seed=\u001b[34m1234\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 创建 DatasetDict 对象，它是 Hugging Face 的 datasets 库中的一个类。DatasetDict 是一个字典，它的键是字符串（如 \"train\"、\"test\"、\"validation\"），值是 Dataset 对象。这样，通过 DatasetDict，可以轻松地管理训练、测试和验证数据集，并能方便地对这些数据集进行操作，如应用相同的预处理函数等。\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    train_test_valid_dataset = DatasetDict(\u001b[37m\u001b[39;49;00m\n",
      "        {\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: train_testvalid[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_valid[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\u001b[37m\u001b[39;49;00m\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: test_valid[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\u001b[37m\u001b[39;49;00m\n",
      "        }\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m数据集划分后的情况:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mtrain_test_valid_dataset\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 创建一个标记化函数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 定义一个 tokenize_function 函数，参数是一个样本\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mtokenize_function\u001b[39;49;00m(example):\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# 定义提示信息\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        prompt = \u001b[33m'\u001b[39;49;00m\u001b[33mSummarize the following conversation.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        end_prompt = \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mSummary: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# 将提示信息添加到对话内容的前后，形成新的输入内容\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        inp = [prompt + i + end_prompt \u001b[34mfor\u001b[39;49;00m i \u001b[35min\u001b[39;49;00m example[\u001b[33m\"\u001b[39;49;00m\u001b[33mdialogue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]]\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# 使用分词器对新的输入内容进行分词，返回的是一个输入ID列表，将其添加到样本字典的 'input_ids' 键中\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# padding=\"max_length\" 表示将分词结果填充到最大长度，truncation=True 表示如果分词结果超过最大长度则截断，return_tensors=\"pt\" 表示返回 PyTorch 张量\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        example[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = tokenizer(inp, padding=\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).input_ids\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# 使用分词器对样本的 'summary' 字段进行分词，返回的是一个标签ID列表，将其添加到样本字典的 'labels' 键中\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        example[\u001b[33m'\u001b[39;49;00m\u001b[33mlabels\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = tokenizer(example[\u001b[33m\"\u001b[39;49;00m\u001b[33msummary\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], padding=\u001b[33m\"\u001b[39;49;00m\u001b[33mmax_length\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, truncation=\u001b[34mTrue\u001b[39;49;00m, return_tensors=\u001b[33m\"\u001b[39;49;00m\u001b[33mpt\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m).input_ids\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m# 返回处理过的样本\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mreturn\u001b[39;49;00m example\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 对数据集进行标记化\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m正在对数据集进行标记化...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 使用 Dataset.map 方法对每个样本应用 tokenize_function 函数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# batched=True 表示以批次方式执行该操作，这样可以加快处理速度\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_datasets = train_test_valid_dataset.map(tokenize_function, batched=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 使用 Dataset.remove_columns 方法删除 'id', 'topic', 'dialogue', 'summary' 这四列\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 因为这些列在之后的模型训练中不再需要\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_datasets = tokenized_datasets.remove_columns([\u001b[33m'\u001b[39;49;00m\u001b[33mid\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtopic\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mdialogue\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33msummary\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m标记化完成！\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 创建保存数据的目录\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    os.makedirs(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/train/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    os.makedirs(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/test/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    os.makedirs(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/validation/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    file_root = \u001b[36mstr\u001b[39;49;00m(\u001b[36mint\u001b[39;49;00m(time.time()*\u001b[34m1000\u001b[39;49;00m))\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 将数据集保存到磁盘\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m正在将数据集写入到 \u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_datasets[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to_parquet(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m./\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/train/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfile_root\u001b[33m}\u001b[39;49;00m\u001b[33m.parquet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_datasets[\u001b[33m'\u001b[39;49;00m\u001b[33mtest\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to_parquet(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m./\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/test/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfile_root\u001b[33m}\u001b[39;49;00m\u001b[33m.parquet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    tokenized_datasets[\u001b[33m'\u001b[39;49;00m\u001b[33mvalidation\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].to_parquet(\u001b[33mf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m./\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_data\u001b[33m}\u001b[39;49;00m\u001b[33m/validation/\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfile_root\u001b[33m}\u001b[39;49;00m\u001b[33m.parquet\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m预处理完成！\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 定义一个 process 函数，参数是一个包含各种参数的对象\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mprocess\u001b[39;49;00m(args):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 打印输入数据的路径，并列出该路径下的所有文件\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mListing contents of \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.input_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dirs_input = os.listdir(args.input_data)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m dirs_input:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(file)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 调用 transform_dataset 函数处理数据\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 输入数据的路径、输出数据的路径、预训练模型名，以及训练集、测试集和验证集的划分比率均从 args 对象中获取\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    transform_dataset(input_data=args.input_data,\u001b[37m\u001b[39;49;00m\n",
      "                      output_data=args.output_data,\u001b[37m\u001b[39;49;00m\n",
      "                      huggingface_model_name=args.model_checkpoint,\u001b[37m\u001b[39;49;00m\n",
      "                      train_split_percentage=args.train_split_percentage,\u001b[37m\u001b[39;49;00m\n",
      "                      test_split_percentage=args.test_split_percentage,\u001b[37m\u001b[39;49;00m\n",
      "                      validation_split_percentage=args.validation_split_percentage\u001b[37m\u001b[39;49;00m\n",
      "                     )\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 打印输出数据的路径，并列出该路径下的所有文件\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mListing contents of \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.output_data\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    dirs_output = os.listdir(args.output_data)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m dirs_output:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(file)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 定义一个 list_arg 函数，参数是一个字符串\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m# 这个函数被用作 argparse 的自定义类型，用于解析一个字符串列表参数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlist_arg\u001b[39;49;00m(raw_value):\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 使用字符串的 split 方法以逗号为分隔符将字符串分割成一个列表，并返回该列表\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mstr\u001b[39;49;00m(raw_value).split(\u001b[33m\"\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "        \u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 首先尝试从 \"/opt/ml/config/resourceconfig.json\" 文件中读取资源配置信息\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 如果该文件不存在，那么将打印一条错误消息并忽略该错误\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    resconfig = {}\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mtry\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/config/resourceconfig.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m cfgfile:\u001b[37m\u001b[39;49;00m\n",
      "            resconfig = json.load(cfgfile)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mFileNotFoundError\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/config/resourceconfig.json not found.  current_host is unknown.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[34mpass\u001b[39;49;00m  \u001b[37m# Ignore\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 创建一个 ArgumentParser 对象\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# argparse.ArgumentParser 是 Python 内置库 argparse 中的一个类，它被用于创建命令行参数和选项解析器。\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser(description=\u001b[33m\"\u001b[39;49;00m\u001b[33mProcess\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 添加各种参数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 注意其中一些参数的默认值是从 resconfig 字典中获取的\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 另外注意 `--hosts` 参数的类型是 list_arg，这是一个自定义的类型，用于解析一个字符串列表参数\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=list_arg,\u001b[37m\u001b[39;49;00m\n",
      "        default=resconfig.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mhosts\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, [\u001b[33m\"\u001b[39;49;00m\u001b[33munknown\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]),\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mComma-separated list of host names running the job\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=resconfig.get(\u001b[33m\"\u001b[39;49;00m\u001b[33mcurrent_host\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33munknown\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m),\u001b[37m\u001b[39;49;00m\n",
      "        help=\u001b[33m\"\u001b[39;49;00m\u001b[33mName of this host running the job\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--input-data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--output-data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/output/data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--train-split-percentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m0.85\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--validation-split-percentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m0.10\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--test-split-percentage\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[34m0.05\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33m--model-checkpoint\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\u001b[37m\u001b[39;49;00m\n",
      "        default=\u001b[33m\"\u001b[39;49;00m\u001b[33mgoogle/flan-t5-base\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    )\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# parser.add_argument(\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     \"--dataset-templates-name\",\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     type=str,\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     default=\"amazon_us_reviews/Wireless_v1_00\",\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# )\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# parser.add_argument(\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     \"--prompt-template-name\",\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     type=str,\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m#     default=\"Given the review body return a categorical rating\",\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# )\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m\u001b[39;49;00m\n",
      "    \u001b[37m# 使用 ArgumentParser 的 parse_args 方法解析命令行参数并返回结果\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "    args = parse_args()\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoaded arguments:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(args)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEnvironment variables:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\u001b[37m\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(os.environ)\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m\u001b[39;49;00m\n",
      "    process(args)\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "# !pygmentize 是一个命令行工具，用于将源代码高亮显示。\n",
    "# 它是 pygments 包的一部分，pygments 是一个 Python 语法高亮的库。该命令需要在命令行环境中运行，例如在一个终端或者 Jupyter notebook 的代码单元格中。\n",
    "# 使用 !pygmentize preprocess.py 命令，将会将 preprocess.py 这个 Python 文件的内容以语法高亮的形式输出。\n",
    "!pygmentize preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将此脚本作为Processing job运行。你还需要指定一个`ProcessingInput`，其`source`参数为Amazon S3存储桶，`destination`是脚本从`/opt/ml/processing/input`（在Docker容器内）读取此数据的位置。处理容器内的所有本地路径必须以`/opt/ml/processing/`开头。\n",
    "\n",
    "还需要给`run()`方法一个`ProcessingOutput`，其中`source`是脚本写入输出数据的路径。对于输出，`destination`默认为Amazon SageMaker Python SDK为你创建的一个S3存储桶，格式为`s3://sagemaker-<region>-<account_id>/<processing_job_name>/output/<output_name>/`。你也可以给`ProcessingOutput`提供`output_name`值，这样在作业运行后更容易检索这些输出工件。\n",
    "\n",
    "`run()`方法中的参数是`preprocess.py`脚本中的命令行参数。\n",
    "\n",
    "注意，我们使用`ShardedByS3Key`对数据进行分片，以在集群中的所有工作节点上分布转换操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置 SageMaker Processing Job 的一些参数\n",
    "# 处理任务使用的机器类型为 \"ml.c5.2xlarge\"\n",
    "processing_instance_type = \"ml.c5.2xlarge\"\n",
    "\n",
    "# 在处理任务中使用的机器数量为 2，即并行执行处理任务的实例数\n",
    "processing_instance_count = 2\n",
    "\n",
    "# 训练集划分的比例为 90%\n",
    "train_split_percentage = 0.9\n",
    "\n",
    "# 验证集划分的比例为 5%\n",
    "validation_split_percentage = 0.05\n",
    "\n",
    "# 测试集划分的比例为 5%\n",
    "test_split_percentage = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 创建一个 SKLearnProcessor 实例，这是一个用于运行 SageMaker Processing Jobs 的处理器。处理器会在指定的实例上运行处理任务。\n",
    "\n",
    "# 导入 SKLearnProcessor 类\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "# 创建一个 SKLearnProcessor 实例\n",
    "processor = SKLearnProcessor(\n",
    "    # 指定 Scikit-learn 框架的版本\n",
    "    framework_version=\"0.23-1\",\n",
    "    \n",
    "    # 指定用于执行 SageMaker Processing Job 的 AWS IAM 角色\n",
    "    role=role,\n",
    "    \n",
    "    # 指定用于执行处理任务的实例类型\n",
    "    instance_type=processing_instance_type,\n",
    "    \n",
    "    # 指定用于执行处理任务的实例数量\n",
    "    instance_count=processing_instance_count,\n",
    "    \n",
    "    # 指定环境变量，这些环境变量将被传递到处理容器中\n",
    "    env={\"AWS_DEFAULT_REGION\": region},\n",
    "    \n",
    "    # 指定处理任务的最大运行时间，单位为秒\n",
    "    max_runtime_in_seconds=7200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 生成一个 S3 路径的字符串，这个路径指向名为 'data-summarization' 的目录，\n",
    "# 这个目录位于名为 'bucket' 的 S3 存储桶中\n",
    "input_s3 = f's3://{bucket}/data-summarization/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-05 03:06:01    6544107 dialogsum-1.csv\n",
      "2023-09-05 03:06:01    6572423 dialogsum-2.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls {input_s3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating processing-job with name sagemaker-scikit-learn-2023-09-08-16-00-28-289\n"
     ]
    }
   ],
   "source": [
    "# 导入 ProcessingInput 和 ProcessingOutput 类\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "# 使用 processor（一个 SKLearnProcessor 实例）运行处理任务\n",
    "processor.run(\n",
    "    # 指定用于执行处理任务的 Python 脚本\n",
    "    code=\"preprocess.py\",\n",
    "    # 指定处理任务的输入数据\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            # 输入数据的名字，可以在处理脚本中使用这个名字来引用这个输入数据\n",
    "            input_name=\"raw-input-data\",\n",
    "            \n",
    "            # 输入数据的 S3 URI\n",
    "            source=raw_input_data_s3_uri,\n",
    "            \n",
    "            # 输入数据将被下载到处理容器的这个目录中\n",
    "            destination=\"/opt/ml/processing/input/data/\",\n",
    "            \n",
    "            # 输入数据的 S3 分发类型，\"ShardedByS3Key\" 表示数据将被均匀地分发到各个实例\n",
    "            s3_data_distribution_type=\"ShardedByS3Key\",\n",
    "        )\n",
    "    ],\n",
    "    # 指定处理任务的输出数据\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            # 输出数据的名字，可以在处理脚本中使用这个名字来引用这个输出数据\n",
    "            output_name=\"train\", \n",
    "            \n",
    "            # 输出数据的 S3 上传模式，\"EndOfJob\" 表示数据将在处理任务结束后上传到 S3\n",
    "            s3_upload_mode=\"EndOfJob\", \n",
    "            \n",
    "            # 处理任务的输出数据将被写入到这个目录中，然后被上传到 S3\n",
    "            source=\"/opt/ml/processing/output/data/train\"\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            s3_upload_mode=\"EndOfJob\",\n",
    "            source=\"/opt/ml/processing/output/data/validation\",\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\", \n",
    "            s3_upload_mode=\"EndOfJob\", \n",
    "            source=\"/opt/ml/processing/output/data/test\"\n",
    "        ),\n",
    "    ],\n",
    "    # 传递给处理脚本的命令行参数\n",
    "    arguments=[\n",
    "        \"--train-split-percentage\",\n",
    "        str(train_split_percentage),\n",
    "        \"--validation-split-percentage\",\n",
    "        str(validation_split_percentage),\n",
    "        \"--test-split-percentage\",\n",
    "        str(test_split_percentage),\n",
    "        \"--model-checkpoint\",\n",
    "        str(model_checkpoint),\n",
    "    ],\n",
    "    # 是否在控制台打印处理任务的日志\n",
    "    logs=True,\n",
    "    \n",
    "    # 是否等待处理任务完成\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-scikit-learn-2023-09-08-16-00-28-289\n"
     ]
    }
   ],
   "source": [
    "# 获取 processor运行的所有处理任务（jobs）列表中的最后一个任务，\n",
    "# 然后调用 describe() 方法获取这个处理任务的详细信息，\n",
    "# 最后从详细信息中获取处理任务的名称（\"ProcessingJobName\"）\n",
    "scikit_processing_job_name = processor.jobs[-1].describe()[\"ProcessingJobName\"]\n",
    "\n",
    "# 打印处理任务的名称\n",
    "print(scikit_processing_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/processing-jobs/sagemaker-scikit-learn-2023-09-08-16-00-28-289\">Processing Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/processing-jobs/{}\">Processing Job</a></b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(\n",
    "            region, scikit_processing_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Processing Job Has Completed</b>'.format(\n",
    "            bucket, scikit_processing_job_name, region\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 监控Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ProcessingInputs': [{'InputName': 'raw-input-data', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-941797585610/data-summarization/', 'LocalPath': '/opt/ml/processing/input/data/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'ShardedByS3Key', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/input/code/preprocess.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/train', 'LocalPath': '/opt/ml/processing/output/data/train', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'validation', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/validation', 'LocalPath': '/opt/ml/processing/output/data/validation', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}, {'OutputName': 'test', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/test', 'LocalPath': '/opt/ml/processing/output/data/test', 'S3UploadMode': 'EndOfJob'}, 'AppManaged': False}]}, 'ProcessingJobName': 'sagemaker-scikit-learn-2023-09-08-16-00-28-289', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 2, 'InstanceType': 'ml.c5.2xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 7200}, 'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3', 'ContainerEntrypoint': ['python3', '/opt/ml/processing/input/code/preprocess.py'], 'ContainerArguments': ['--train-split-percentage', '0.9', '--validation-split-percentage', '0.05', '--test-split-percentage', '0.05', '--model-checkpoint', 'google/flan-t5-base']}, 'Environment': {'AWS_DEFAULT_REGION': 'us-east-1'}, 'RoleArn': 'arn:aws:iam::941797585610:role/service-role/AmazonSageMaker-ExecutionRole-20230420T182274', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:941797585610:processing-job/sagemaker-scikit-learn-2023-09-08-16-00-28-289', 'ProcessingJobStatus': 'Completed', 'ProcessingEndTime': datetime.datetime(2023, 9, 8, 16, 7, 10, 639000, tzinfo=tzlocal()), 'ProcessingStartTime': datetime.datetime(2023, 9, 8, 16, 5, 11, 348000, tzinfo=tzlocal()), 'LastModifiedTime': datetime.datetime(2023, 9, 8, 16, 7, 10, 941000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2023, 9, 8, 16, 0, 28, 879000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': '9a02906c-b4b7-47cc-b42a-95cb1ec1254e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9a02906c-b4b7-47cc-b42a-95cb1ec1254e', 'content-type': 'application/x-amz-json-1.1', 'content-length': '2631', 'date': 'Fri, 08 Sep 2023 16:07:42 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# 使用 ProcessingJob 类的 from_processing_name 方法根据处理任务的名称创建一个 ProcessingJob 实例。\n",
    "# 这个方法需要两个参数：处理任务的名称和一个 SageMaker 会话（sagemaker_session）。\n",
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(\n",
    "    processing_job_name=scikit_processing_job_name, sagemaker_session=sess\n",
    ")\n",
    "\n",
    "# 调用 ProcessingJob 实例的 describe 方法获取处理任务的详细信息。\n",
    "# 这个方法返回一个包含了处理任务详细信息的字典。\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "# 打印处理任务的详细信息。\n",
    "print(processing_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!"
     ]
    }
   ],
   "source": [
    "# 使用 ProcessingJob 实例的 wait 方法等待处理任务完成。\n",
    "# 这个方法会阻塞当前线程，直到处理任务完成。\n",
    "# 参数 logs=False 表示在等待处理任务完成时不打印处理任务的日志。\n",
    "running_processor.wait(logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait Until the ^^ Processing Job ^^ Completes Above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检查处理后的输出数据\n",
    "\n",
    "查看转换后数据集，以确保处理成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/train\n",
      "s3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/validation\n",
      "s3://sagemaker-us-east-1-941797585610/sagemaker-scikit-learn-2023-09-08-16-00-28-289/output/test\n"
     ]
    }
   ],
   "source": [
    "# 再次调用 ProcessingJob 实例的 describe 方法获取处理任务的详细信息。\n",
    "# 这个方法返回一个包含了处理任务详细信息的字典。\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "# 从处理任务的详细信息中获取输出数据的配置信息。\n",
    "output_config = processing_job_description[\"ProcessingOutputConfig\"]\n",
    "\n",
    "# 遍历输出数据的配置信息\n",
    "for output in output_config[\"Outputs\"]:\n",
    "    # 如果输出数据的名字是 \"train\"，那么获取这个输出数据的 S3 URI，并保存到变量 processed_train_data_s3_uri 中\n",
    "    if output[\"OutputName\"] == \"train\":\n",
    "        processed_train_data_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "    # 如果输出数据的名字是 \"validation\"，那么获取这个输出数据的 S3 URI，并保存到变量 processed_validation_data_s3_uri 中\n",
    "    if output[\"OutputName\"] == \"validation\":\n",
    "        processed_validation_data_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "    # 如果输出数据的名字是 \"test\"，那么获取这个输出数据的 S3 URI，并保存到变量 processed_test_data_s3_uri 中\n",
    "    if output[\"OutputName\"] == \"test\":\n",
    "        processed_test_data_s3_uri = output[\"S3Output\"][\"S3Uri\"]\n",
    "\n",
    "# 打印处理后的训练数据的 S3 URI\n",
    "print(processed_train_data_s3_uri)\n",
    "# 打印处理后的验证数据的 S3 URI\n",
    "print(processed_validation_data_s3_uri)\n",
    "# 打印处理后的测试数据的 S3 URI\n",
    "print(processed_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-08 16:07:05    2540571 1694189218128.parquet\n",
      "2023-09-08 16:07:04    2545157 1694189219320.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_train_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-08 16:07:05     150701 1694189218128.parquet\n",
      "2023-09-08 16:07:04     150220 1694189219320.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_validation_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-08 16:07:06     157115 1694189218128.parquet\n",
      "2023-09-08 16:07:05     153865 1694189219320.parquet\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $processed_test_data_s3_uri/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 将变量传递给下一个笔记本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'raw_input_data_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store raw_input_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_split_percentage' (float)\n"
     ]
    }
   ],
   "source": [
    "%store train_split_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'validation_split_percentage' (float)\n"
     ]
    }
   ],
   "source": [
    "%store validation_split_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_split_percentage' (float)\n"
     ]
    }
   ],
   "source": [
    "%store test_split_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %store balance_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'processed_train_data_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'processed_validation_data_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'processed_test_data_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "ingest_create_athena_table_parquet_passed             -> True\n",
      "local_data_processed_path                             -> './data-summarization-processed/'\n",
      "model_checkpoint                                      -> 'google/flan-t5-base'\n",
      "processed_test_data_s3_uri                            -> 's3://sagemaker-us-east-1-941797585610/sagemaker-s\n",
      "processed_train_data_s3_uri                           -> 's3://sagemaker-us-east-1-941797585610/sagemaker-s\n",
      "processed_validation_data_s3_uri                      -> 's3://sagemaker-us-east-1-941797585610/sagemaker-s\n",
      "raw_input_data_s3_uri                                 -> 's3://sagemaker-us-east-1-941797585610/data-summar\n",
      "role                                                  -> 'arn:aws:iam::941797585610:role/service-role/Amazo\n",
      "s3_private_path_tsv                                   -> 's3://sagemaker-us-east-1-941797585610/amazon-revi\n",
      "s3_public_path_tsv                                    -> 's3://dsoaws/tsv'\n",
      "setup_dependencies_passed                             -> True\n",
      "supervised_fine_tuned_model_path                      -> './flan-dialogue-summary-checkpoint'\n",
      "test_split_percentage                                 -> 0.05\n",
      "train_split_percentage                                -> 0.9\n",
      "validation_split_percentage                           -> 0.05\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
